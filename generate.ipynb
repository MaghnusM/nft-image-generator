{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "dlopen(/Users/maghnus/Library/Python/3.8/lib/python/site-packages/PIL/_imaging.cpython-38-darwin.so, 0x0002): tried: '/Users/maghnus/Library/Python/3.8/lib/python/site-packages/PIL/_imaging.cpython-38-darwin.so' (mach-o file, but is an incompatible architecture (have 'arm64', need 'x86_64')), '/usr/local/lib/_imaging.cpython-38-darwin.so' (no such file), '/usr/lib/_imaging.cpython-38-darwin.so' (no such file)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/k7/vhg5273j3s9dy2vlqsjhc7kc0000gn/T/ipykernel_83594/3085502784.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;31m# Also note that Image.core is not a publicly documented interface,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;31m# and should be considered private and subject to change.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_imaging\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"PILLOW_VERSION\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: dlopen(/Users/maghnus/Library/Python/3.8/lib/python/site-packages/PIL/_imaging.cpython-38-darwin.so, 0x0002): tried: '/Users/maghnus/Library/Python/3.8/lib/python/site-packages/PIL/_imaging.cpython-38-darwin.so' (mach-o file, but is an incompatible architecture (have 'arm64', need 'x86_64')), '/usr/local/lib/_imaging.cpython-38-darwin.so' (no such file), '/usr/lib/_imaging.cpython-38-darwin.so' (no such file)"
     ]
    }
   ],
   "source": [
    "from IPython.display import display \n",
    "import random\n",
    "import json\n",
    "import string\n",
    "import os\n",
    "from PIL import Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "traits_dict = {}\n",
    "\n",
    "# trait_types = os.listdir(\"trait-layers/\")\n",
    "trait_types = [\n",
    "    '1|1',\n",
    "    'canvas',\n",
    "    'door',\n",
    "    'background',\n",
    "    'message',\n",
    "    'type',\n",
    "    'eyes',\n",
    "    'beard',\n",
    "    'right hand',\n",
    "    'base',\n",
    "    'headphones',\n",
    "    'long hair',\n",
    "    'hat under headphones',\n",
    "    'short hair',\n",
    "    'hat over headphones',\n",
    "    'shirt',\n",
    "    'smoke',\n",
    "    'message'\n",
    "]\n",
    "\n",
    "specials = [\"graveyard\", \"space\", \"tree\"]\n",
    "\n",
    "for trait_type in trait_types:\n",
    "    if trait_type != \".DS_Store\":\n",
    "        traits_dict[trait_type] = [str.replace('.png', '').lower() for str in os.listdir(\"trait-layers/{}/\".format(trait_type)) if str != \".DS_Store\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate Traits\n",
    "\n",
    "json_dict = {}\n",
    "\n",
    "# get the actual mfers traits as JSON\n",
    "with open(\"test.json\") as json_raw:\n",
    "    json_dict = json.load(json_raw)\n",
    "    TOTAL_IMAGES = len(json_dict)\n",
    "\n",
    "all_images = [] \n",
    "\n",
    "# A recursive function to generate unique image combinations\n",
    "def create_new_image(tokenid):\n",
    "    \n",
    "    new_image = {}\n",
    "    \n",
    "#     Now a list of the form [{'trait_type': 'background', 'value': 'red'}] etc\n",
    "    if \"{}\".format(tokenid) in json_dict:\n",
    "        mfer_attrs = json_dict[\"{}\".format(tokenid)][\"attributes\"]\n",
    "    else:\n",
    "        mfer_attrs = [{'trait_type': '1|1', 'value': 'None'}]\n",
    "        \n",
    "    print(\"mfer attrs\")\n",
    "    print(mfer_attrs)\n",
    "    \n",
    "    for dic in mfer_attrs:\n",
    "        \n",
    "        temp = dic[\"trait_type\"]\n",
    "        temp = temp.replace(\"/\", \"|\")\n",
    "        dic[\"trait_type\"] = temp.lower()\n",
    "        \n",
    "        if dic[\"trait_type\"] in traits_dict:\n",
    "            \n",
    "            temp = dic[\"value\"]\n",
    "            dic[\"value\"] = temp.lower()\n",
    "            \n",
    "            # replace word mfer with dadmfer\n",
    "            if dic[\"trait_type\"] == \"type\":\n",
    "                temp = dic[\"value\"]\n",
    "                dic[\"value\"] = temp.replace(\" mfer\", \" dadmfer\")\n",
    "                print(dic[\"value\"])\n",
    "                \n",
    "            if dic[\"trait_type\"] == \"1|1\":\n",
    "                new_image[dic[\"trait_type\"]] = \"None\" # \"''.join(random.choice(string.ascii_lowercase) for i in range(20))\n",
    "                \n",
    "            # replace / with |\n",
    "            if \"/\" in dic[\"value\"]:\n",
    "                temp = dic[\"value\"]\n",
    "                dic[\"value\"] = temp.replace(\"/\", \"|\")\n",
    "            \n",
    "            \n",
    "            if dic[\"value\"] in traits_dict[dic[\"trait_type\"]]:\n",
    "                new_image[dic[\"trait_type\"]] = dic[\"value\"]\n",
    "            else:\n",
    "                print(mfer_attrs)\n",
    "                print(\"dont have value {} with trait {}\".format(dic[\"value\"], dic[\"trait_type\"]))\n",
    "        else:\n",
    "            print(mfer_attrs)\n",
    "            print(\"dont have type {}\".format(dic[\"trait_type\"]))\n",
    "    \n",
    "    new_image[\"base\"] = \"skeleton\"\n",
    "    avail_canvases = traits_dict[\"canvas\"].copy()\n",
    "    \n",
    "    print(\"-----\")\n",
    "    print(tokenid)\n",
    "    print(mfer_attrs)\n",
    "    print(new_image)\n",
    "    print(\"-----\")\n",
    "    \n",
    "    if \"1|1\" in new_image:\n",
    "        new_image[\"background\"] = \"orange\"\n",
    "        new_image[\"canvas\"] = \"orange\"\n",
    "        new_image[\"door\"] = \"orange\"\n",
    "        new_image[\"message\"] = \"klingon\"\n",
    "        \n",
    "    else:\n",
    "    \n",
    "        # canvas cannot match background\n",
    "        if new_image[\"background\"] in avail_canvases:\n",
    "            avail_canvases = [name for name in avail_canvases if name not in specials]\n",
    "\n",
    "            if new_image[\"background\"] not in specials:\n",
    "                avail_canvases.remove(new_image[\"background\"])\n",
    "\n",
    "            new_image[\"canvas\"] = random.choice(avail_canvases)\n",
    "\n",
    "        avail_doors = traits_dict[\"door\"].copy()\n",
    "        if new_image[\"background\"] in avail_doors:\n",
    "            avail_doors = [name for name in avail_doors if name not in specials]\n",
    "\n",
    "            if new_image[\"background\"] not in specials:\n",
    "                avail_doors.remove(new_image[\"background\"])\n",
    "\n",
    "            print(new_image[\"canvas\"])\n",
    "            avail_doors.remove(new_image[\"canvas\"])\n",
    "            new_image[\"door\"] = random.choice(avail_doors)\n",
    "\n",
    "        # MESSAGE\n",
    "        new_image[\"message\"] = \"dads gotta know!\"\n",
    "\n",
    "        if new_image[\"type\"] == \"zombie dadmfer\":\n",
    "            new_image[\"canvas\"] = \"graveyard\"\n",
    "            new_image[\"door\"] = \"graveyard\"\n",
    "            new_image[\"message\"] = \"back from the ded\"\n",
    "\n",
    "        if new_image[\"type\"] == \"alien dadmfer\":\n",
    "            new_image[\"canvas\"] = \"space\"\n",
    "            new_image[\"door\"] = \"space\"\n",
    "            new_image[\"message\"] = \"klingon\"\n",
    "\n",
    "        if new_image[\"type\"] == \"ape dadmfer\":\n",
    "            new_image[\"canvas\"] = \"tree\"\n",
    "            new_image[\"door\"] = \"tree\"\n",
    "            new_image[\"message\"] = \"sus talk\"\n",
    "\n",
    "        # RIGHT HAND\n",
    "        new_image[\"right hand\"] = random.choice(traits_dict[\"right hand\"])\n",
    "\n",
    "    return new_image\n",
    "    \n",
    "    \n",
    "# Generate the unique combinations based on trait weightings\n",
    "for i in range(0, TOTAL_IMAGES): \n",
    "    \n",
    "    new_trait_image = create_new_image(i)\n",
    "    \n",
    "    all_images.append(new_trait_image)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns true if all images are unique\n",
    "def all_images_unique(all_images):\n",
    "    seen = list()\n",
    "    return not any(i in seen or seen.append(i) for i in all_images)\n",
    "\n",
    "print(\"Are all images unique?\", all_images_unique(all_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add token Id to each image\n",
    "i = 0\n",
    "for item in all_images:\n",
    "    item[\"tokenId\"] = i\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Trait Counts\n",
    "\n",
    "counts = {}\n",
    "\n",
    "for k in traits_dict:\n",
    "    counts[k] = {}\n",
    "    for item in traits_dict[k]:\n",
    "        counts[k][item] = 0\n",
    "        \n",
    "for image in all_images:\n",
    "    for k in traits_dict:\n",
    "        if k in image:\n",
    "#             TODO REMEMBER THAT YOU TOOK OUT SPECIAL BACKGROUNDS ETC\n",
    "            if k in counts and image[k] in counts[k]:\n",
    "                counts[k][image[k]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Generate Metadata for all Traits \n",
    "METADATA_FILE_NAME = './metadata/all-traits.json'; \n",
    "with open(METADATA_FILE_NAME, 'w') as outfile:\n",
    "    json.dump(all_images, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "    \n",
    "#### Generate Images    \n",
    "for item in all_images[6580:]:\n",
    "    \n",
    "    print(\"item\")\n",
    "    print(item)\n",
    "    \n",
    "    image_list = []\n",
    "    \n",
    "    max = 0\n",
    "    for k in trait_types:\n",
    "        if k in item:\n",
    "            image_list += [Image.open(f'./trait-layers/{k}/{item[k].lower()}.png').convert('RGBA')]\n",
    "            max += 1\n",
    "\n",
    "    #Create each composite\n",
    "    \n",
    "    comp = Image.alpha_composite(image_list[0], image_list[1])\n",
    "    for i in range(2, max):\n",
    "        comp = Image.alpha_composite(comp, image_list[i])\n",
    "\n",
    "    #Convert to RGB\n",
    "    rgb_im = comp.convert('RGB')\n",
    "    file_name = str(item[\"tokenId\"]) + \".png\"\n",
    "    rgb_im.save(\"./images/\" + file_name)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Generate Metadata for each Image    \n",
    "\n",
    "f = open('./metadata/all-traits.json',) \n",
    "data = json.load(f)\n",
    "\n",
    "\n",
    "IMAGES_BASE_URI = \"ADD_IMAGES_BASE_URI_HERE\"\n",
    "PROJECT_NAME = \"ADD_PROJECT_NAME_HERE\"\n",
    "\n",
    "def getAttribute(key, value):\n",
    "    return {\n",
    "        \"trait_type\": key,\n",
    "        \"value\": value\n",
    "    }\n",
    "for i in data:\n",
    "    token_id = i['tokenId']\n",
    "    token = {\n",
    "        \"image\": IMAGES_BASE_URI + str(token_id) + '.png',\n",
    "        \"tokenId\": token_id,\n",
    "        \"name\": PROJECT_NAME + ' ' + str(token_id),\n",
    "        \"attributes\": []\n",
    "    }\n",
    "#     token[\"attributes\"].append(getAttribute(\"Background\", i[\"Background\"]))\n",
    "#     token[\"attributes\"].append(getAttribute(\"Circle\", i[\"Circle\"]))\n",
    "#     token[\"attributes\"].append(getAttribute(\"Square\", i[\"Square\"]))\n",
    "\n",
    "    with open('./metadata/' + str(token_id), 'w') as outfile:\n",
    "        json.dump(token, outfile, indent=4)\n",
    "f.close()\n",
    "\n",
    "\n",
    "    # HEAD CHOICES\n",
    "#     head_type = random.choice([1, 2, 3, 4])\n",
    "#     if head_type == 1:\n",
    "#         # keep short hair\n",
    "#         new_image.pop(\"Hat over headphones\")\n",
    "#         new_image.pop(\"Hat under headphones\")\n",
    "#         new_image.pop(\"Long hair\")\n",
    "#     if head_type == 2:\n",
    "#         # keep long hair\n",
    "#         new_image.pop(\"Hat over headphones\")\n",
    "#         new_image.pop(\"Hat under headphones\")\n",
    "#         new_image.pop(\"Short hair\")\n",
    "#     if head_type == 3:\n",
    "#         # keep over headphones\n",
    "#         new_image.pop(\"Short hair\")\n",
    "#         new_image.pop(\"Hat under headphones\")\n",
    "#         new_image.pop(\"Long hair\")\n",
    "#     if head_type == 4:\n",
    "#         # keep under headphones\n",
    "#         new_image.pop(\"Short hair\")\n",
    "#         new_image.pop(\"Hat over headphones\")\n",
    "#         new_image.pop(\"Long hair\")\n",
    "        \n",
    "    \n",
    "    # APE / ZOMBIE / ALIEN COHESIVENESS\n",
    "    \n",
    "#     if new_image[\"Type\"] == \"Alien dadmfer\":\n",
    "#         new_image[\"Background\"] = \"Alien\"\n",
    "#     if new_image[\"Type\"] == \"Zombie dadmfer\":\n",
    "#         new_image[\"Background\"] = \"Zombie\"\n",
    "#     if new_image[\"Type\"] == \"Ape dadmfer\":\n",
    "#         new_image[\"Background\"] = \"Tree\"\n",
    "        \n",
    "    # OTHER RULES\n",
    "    \n",
    "#     if \"Hat over headphones\" in new_image:\n",
    "#         if new_image[\"Hat over headphones\"] == \"Pilot helmet\":\n",
    "#             new_image.pop(\"Headphones\")\n",
    "\n",
    "    # For each trait category, select a random trait based on the weightings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3d65f8beab89bca824669a8319117cabe601d9aca9a71aad8efeb42336828120"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
